"""
åŠŸèƒ½æµç¨‹ï¼š
1. è¾“å…¥è‡ªç„¶è¯­è¨€å¥å­
2. ä¸examplesä¸­çš„å¥å­è®¡ç®—ç›¸ä¼¼åº¦ï¼Œæå–æœ€ç›¸ä¼¼çš„5ä¸ªä½œä¸ºç¤ºä¾‹
3. å››é˜¶æ®µå¤„ç†ï¼š
   - ç¬¬ä¸€é˜¶æ®µï¼šä¸‰ä¸ªAgentç‹¬ç«‹åˆ†æ
   - ç¬¬äºŒé˜¶æ®µï¼šAgentç›¸äº’è®¨è®ºï¼ˆæœ€å¤š5è½®ï¼‰
   - ç¬¬ä¸‰é˜¶æ®µï¼šAgentæŠ•ç¥¨
   - ç¬¬å››é˜¶æ®µï¼šä»²è£Agenté€‰æ‹©æœ€ä½³ç»“æœ
4. ç»Ÿè®¡å…¨ç¨‹tokenæ¶ˆè€—
"""

import json
import time
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path
from sentence_transformers import SentenceTransformer, util
from openai import OpenAI
from dotenv import load_dotenv
import logging
import os
import re
from dotenv import load_dotenv

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class HumanDecision(Enum):
    """äººå·¥å†³ç­–é€‰é¡¹"""
    CONTINUE = "continue"
    TERMINATE = "terminate"

@dataclass
class TokenUsage:
    """Tokenä½¿ç”¨ç»Ÿè®¡"""
    prompt_tokens: int = 0
    completion_tokens: int = 0
    total_tokens: int = 0

@dataclass
class StageResult:
    """é˜¶æ®µç»“æœ"""
    stage_name: str
    agent_responses: Dict[str, str]
    token_usage: TokenUsage
    processing_time: float
    human_decision: Optional[HumanDecision] = None
    candidate_details: Optional[Dict[str, Dict[str, str]]] = None

@dataclass
class ProcessResult:
    """å¤„ç†ç»“æœ"""
    input_sentence: str
    final_mtl_expression: Optional[str]
    total_token_usage: TokenUsage
    total_processing_time: float
    stage_results: List[StageResult]
    termination_reason: str

class SimplifiedNL2MTL:
    """ç®€åŒ–ç‰ˆNL2MTLå¤„ç†å™¨"""
    
    def __init__(self, config_path: str = "config/config.json"):
        """åˆå§‹åŒ–å¤„ç†å™¨"""
        self.config = self._load_config(config_path)
        self.sentence_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
        self.clients = self._initialize_clients()
        self.agents = self._initialize_agents()
        self.examples_data = self._load_examples()
        self.base_prompt = self._load_base_prompt()
        self.total_token_usage = TokenUsage()
        
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.warning(f"é…ç½®æ–‡ä»¶ {config_path} æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "agents": [
                {
                    "name": "Agent_A",
                    "role": "logician",
                    "model": "deepseek-chat",
                    "temperature": 0.7,
                    "api_key_env": "DEEPSEEK_API_KEY",
                    "base_url_env": "DEEPSEEK_API_URL"
                },
                {
                    "name": "Agent_B", 
                    "role": "creative",
                    "model": "deepseek-chat",
                    "temperature": 0.7,
                    "api_key_env": "DEEPSEEK_API_KEY",
                    "base_url_env": "DEEPSEEK_API_URL"
                },
                {
                    "name": "Agent_C",
                    "role": "pragmatic", 
                    "model": "deepseek-chat",
                    "temperature": 0.7,
                    "api_key_env": "DEEPSEEK_API_KEY",
                    "base_url_env": "DEEPSEEK_API_URL"
                }
            ]
        }
    
    def _initialize_clients(self) -> Dict[str, OpenAI]:
        """åˆå§‹åŒ–APIå®¢æˆ·ç«¯"""
        load_dotenv()
        clients = {}
        
        for agent_config in self.config["agents"]:
            api_key = os.getenv(agent_config["api_key_env"])
            base_url = os.getenv(agent_config["base_url_env"])
            
            if api_key:
                clients[agent_config["name"]] = OpenAI(
                    api_key=api_key,
                    base_url=base_url
                )
            else:
                logger.warning(f"APIå¯†é’¥æœªæ‰¾åˆ°: {agent_config['api_key_env']}")
                
        return clients
    
    def _initialize_agents(self) -> List[Dict]:
        """åˆå§‹åŒ–Agenté…ç½®"""
        agents = []
        role_prompts = {
            "logician": "ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„é€»è¾‘å­¦å®¶ï¼Œç”¨ä¸¥æ ¼çš„é€»è¾‘æ¨ç†åˆ†æé—®é¢˜ã€‚",
            "creative": "ä½ æ˜¯ä¸€ä¸ªåˆ›é€ æ€§æ€è€ƒè€…ï¼Œè€ƒè™‘å¤šç§è§£é‡Šå’Œå¯èƒ½æ€§ã€‚",
            "pragmatic": "ä½ æ˜¯ä¸€ä¸ªå®ç”¨ä¸»ä¹‰åˆ†æå¸ˆï¼Œä¸“æ³¨äºå¸¸è¯†æ€§è§£é‡Šã€‚"
        }
        
        for agent_config in self.config["agents"]:
            agents.append({
                "name": agent_config["name"],
                "role": agent_config["role"],
                "model": agent_config["model"],
                "temperature": agent_config["temperature"],
                "system_prompt": role_prompts.get(agent_config["role"], "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚")
            })
            
        return agents
    
    def _load_examples(self) -> pd.DataFrame:
        """åŠ è½½ç¤ºä¾‹æ•°æ®"""
        try:
            return pd.read_excel("data/input/examples.xlsx")
        except FileNotFoundError:
            logger.error("ç¤ºä¾‹æ–‡ä»¶æœªæ‰¾åˆ°: data/input/examples.xlsx")
            return pd.DataFrame(columns=["Natural language traffic rule", "Answer"])
    
    def _load_base_prompt(self) -> str:
        """åŠ è½½åŸºç¡€promptæ¨¡æ¿"""
        try:
            with open("config/base_prompt.txt", 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            logger.warning("åŸºç¡€promptæ–‡ä»¶æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤prompt")
            return """è¯·åˆ†æä»¥ä¸‹å¥å­å¹¶ç”Ÿæˆå¯¹åº”çš„MTLè¡¨è¾¾å¼ã€‚

å¥å­: [INPUT TEXT]

ç¤ºä¾‹:
[EXAMPLE]

è¯·æä¾›è¯¦ç»†çš„åˆ†æè¿‡ç¨‹å’Œæœ€ç»ˆçš„MTLè¡¨è¾¾å¼ã€‚"""
    
    def _calculate_similarity(self, sentence: str, examples: List[str]) -> List[float]:
        """è®¡ç®—å¥å­ä¸ç¤ºä¾‹çš„ç›¸ä¼¼åº¦"""
        try:
            # ç¼–ç è¾“å…¥å¥å­å’Œæ‰€æœ‰ç¤ºä¾‹
            sentence_embedding = self.sentence_model.encode([sentence], convert_to_tensor=True)
            example_embeddings = self.sentence_model.encode(examples, convert_to_tensor=True)
            
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            similarities = util.pytorch_cos_sim(sentence_embedding, example_embeddings)[0]
            return similarities.cpu().numpy().tolist()
        except Exception as e:
            logger.error(f"ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
            return [0.0] * len(examples)
    
    def _get_top_examples(self, sentence: str, top_k: int = 5) -> str:
        """è·å–æœ€ç›¸ä¼¼çš„top-kä¸ªç¤ºä¾‹"""
        if self.examples_data.empty:
            return "æ— å¯ç”¨ç¤ºä¾‹"
        
        examples = self.examples_data["Natural language traffic rule"].tolist()
        answers = self.examples_data["Answer"].tolist()
        
        similarities = self._calculate_similarity(sentence, examples)
        
        # è·å–top-kç´¢å¼•
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        # æ„å»ºç¤ºä¾‹æ–‡æœ¬
        example_text = ""
        for i, idx in enumerate(top_indices, 1):
            example_text += f"ç¤ºä¾‹{i}:\n"
            example_text += f"Input Text: {examples[idx]}\n"
            example_text += f"Answer: {answers[idx]}\n\n"
        
        return example_text
    
    def _call_llm(self, agent_name: str, messages: List[Dict]) -> Tuple[str, TokenUsage]:
        """è°ƒç”¨LLMå¹¶è¿½è¸ªtokenä½¿ç”¨"""
        if agent_name not in self.clients:
            raise ValueError(f"å®¢æˆ·ç«¯æœªæ‰¾åˆ°: {agent_name}")
            
        client = self.clients[agent_name]
        agent = next(a for a in self.agents if a["name"] == agent_name)
        
        try:
            response = client.chat.completions.create(
                model=agent["model"],
                messages=messages,  # type: ignore
                temperature=agent["temperature"]
            )
            
            # è¿½è¸ªtokenä½¿ç”¨
            token_usage = TokenUsage()
            if hasattr(response, 'usage') and response.usage:
                token_usage.prompt_tokens = response.usage.prompt_tokens
                token_usage.completion_tokens = response.usage.completion_tokens
                token_usage.total_tokens = response.usage.total_tokens
            
            # ç´¯è®¡åˆ°æ€»ä½¿ç”¨é‡
            self.total_token_usage.prompt_tokens += token_usage.prompt_tokens
            self.total_token_usage.completion_tokens += token_usage.completion_tokens
            self.total_token_usage.total_tokens += token_usage.total_tokens
            
            content = response.choices[0].message.content
            return content.strip() if content else "", token_usage
            
        except Exception as e:
            logger.error(f"LLMè°ƒç”¨å¤±è´¥ {agent_name}: {e}")
            return "", TokenUsage()
    
    def _extract_mtl_expression(self, response: str) -> str:
        """ä»å›ç­”ä¸­æå–MTLè¡¨è¾¾å¼"""
        # å°è¯•æå–```åŒ…å›´çš„MTLè¡¨è¾¾å¼
        mtl_match = re.search(r'```(.*?)```', response, re.DOTALL)
        if mtl_match:
            return mtl_match.group(1).strip()
        
        # å°è¯•æå–MTL translation: åé¢çš„å†…å®¹
        mtl_match = re.search(r'MTL translation:\s*(.+)', response, re.IGNORECASE)
        if mtl_match:
            return mtl_match.group(1).strip()
        
        # å°è¯•æå–åŒ…å«G(ã€F_ã€P_ç­‰MTLæ“ä½œç¬¦çš„è¡Œ
        lines = response.split('\n')
        for line in lines:
            if any(op in line for op in ['G(', 'F_[', 'P_[', 'U_[', 'X(']):
                return line.strip()
        
        return "æœªæ‰¾åˆ°MTLè¡¨è¾¾å¼"

    def _extract_vote_info(self, response: str) -> Dict[str, str]:
        """ä»æŠ•ç¥¨å›ç­”ä¸­æå–æŠ•ç¥¨ä¿¡æ¯"""
        vote_info = {"vote": "æœªè¯†åˆ«", "reason": "æœªæä¾›ç†ç”±"}
        
        # å°è¯•æå–æŠ•ç¥¨é€‰æ‹©
        vote_patterns = [
            r'æˆ‘æŠ•ç¥¨ç»™[ï¼š:]?\s*([^ï¼Œ,\n]+)',
            r'æŠ•ç¥¨[ï¼š:]?\s*([^ï¼Œ,\n]+)',
            r'é€‰æ‹©[ï¼š:]?\s*([^ï¼Œ,\n]+)',
            r'å€™é€‰\d+',
        ]
        
        for pattern in vote_patterns:
            match = re.search(pattern, response, re.IGNORECASE)
            if match:
                vote_info["vote"] = match.group(1).strip() if match.groups() else match.group(0).strip()
                break
        
        # å°è¯•æå–æŠ•ç¥¨ç†ç”±
        reason_patterns = [
            r'ç†ç”±[ï¼š:]?\s*([^ã€‚\n]+)',
            r'å› ä¸º\s*([^ã€‚\n]+)',
            r'åŸå› [ï¼š:]?\s*([^ã€‚\n]+)',
        ]
        
        for pattern in reason_patterns:
            match = re.search(pattern, response, re.IGNORECASE)
            if match:
                vote_info["reason"] = match.group(1).strip()
                break
        
        return vote_info

    def _display_voting_details(self, agent_responses: Dict[str, str]) -> None:
        """æ˜¾ç¤ºæŠ•ç¥¨è¯¦ç»†ä¿¡æ¯"""
        print("\nğŸ—³ï¸  æŠ•ç¥¨è¯¦æƒ…:")
        print("-" * 50)
        
        vote_summary = {}
        for agent_name, response in agent_responses.items():
            vote_info = self._extract_vote_info(response)
            vote_choice = vote_info["vote"]
            vote_reason = vote_info["reason"]
            
            print(f"\nã€{agent_name}ã€‘:")
            print(f"ğŸ¯ æŠ•ç¥¨é€‰æ‹©: {vote_choice}")
            print(f"ğŸ’­ æŠ•ç¥¨ç†ç”±: {vote_reason}")
            
            # ç»Ÿè®¡æŠ•ç¥¨
            if vote_choice in vote_summary:
                vote_summary[vote_choice] += 1
            else:
                vote_summary[vote_choice] = 1
            
            print("-" * 30)
        
        # æ˜¾ç¤ºæŠ•ç¥¨ç»Ÿè®¡
        if vote_summary:
            print(f"\nğŸ“Š æŠ•ç¥¨ç»Ÿè®¡:")
            for choice, count in sorted(vote_summary.items(), key=lambda x: x[1], reverse=True):
                print(f"   {choice}: {count} ç¥¨")
    
    def _display_discussion_summary(self, agent_responses: Dict[str, str]) -> None:
        """æ˜¾ç¤ºè®¨è®ºé˜¶æ®µæ‘˜è¦"""
        print("\nğŸ’¬ è®¨è®ºç»“æœæ‘˜è¦:")
        print("-" * 50)
        
        mtl_expressions = []
        for agent_name, response in agent_responses.items():
            mtl_expr = self._extract_mtl_expression(response)
            mtl_expressions.append(mtl_expr)
            
            print(f"\nã€{agent_name}ã€‘:")
            print(f"ğŸ¯ æœ€ç»ˆMTLè¡¨è¾¾å¼: {mtl_expr}")
            
            # æ˜¾ç¤ºè®¨è®ºè¦ç‚¹ï¼ˆå‰200å­—ç¬¦ï¼‰
            print(f"ğŸ’­ è®¨è®ºè¦ç‚¹:")
            if len(response) > 200:
                print(f"{response[:200]}...")
            else:
                print(response)
            print("-" * 30)
        
        # æ£€æŸ¥æ˜¯å¦è¾¾æˆå…±è¯†
        unique_expressions = set(expr for expr in mtl_expressions if expr != "æœªæ‰¾åˆ°MTLè¡¨è¾¾å¼")
        if len(unique_expressions) == 1 and unique_expressions:
            print(f"\nâœ… è®¨è®ºè¾¾æˆå…±è¯†: {list(unique_expressions)[0]}")
        elif len(unique_expressions) > 1:
            print(f"\nâš ï¸  ä»å­˜åœ¨åˆ†æ­§ï¼Œå…±æœ‰ {len(unique_expressions)} ç§ä¸åŒè§‚ç‚¹")
        else:
            print(f"\nâŒ æœªèƒ½æå–åˆ°æœ‰æ•ˆçš„MTLè¡¨è¾¾å¼")
    
    def _request_human_decision(self, stage_name: str, results: Dict[str, Any],
                               agent_responses: Optional[Dict[str, str]] = None,
                               stage_result: Optional[StageResult] = None) -> HumanDecision:
        """è¯·æ±‚äººå·¥å†³ç­–"""
        print(f"\n{'='*60}")
        print(f"ğŸ¤” äººå·¥å†³ç­–è¯·æ±‚ - {stage_name}")
        print(f"{'='*60}")
        
        # æ˜¾ç¤ºAgentçš„å…·ä½“å›ç­”
        if agent_responses:
            if "æŠ•ç¥¨" in stage_name:
                # æŠ•ç¥¨é˜¶æ®µå…ˆæ˜¾ç¤ºå€™é€‰é¡¹è¯¦æƒ…ï¼Œå†æ˜¾ç¤ºæŠ•ç¥¨è¯¦æƒ…
                if stage_result and hasattr(stage_result, 'candidate_details') and stage_result.candidate_details:
                    print("\nğŸ“‹ æŠ•ç¥¨å€™é€‰é¡¹:")
                    print("-" * 50)
                    for cand_id, details in stage_result.candidate_details.items():
                        print(f"\nã€{cand_id}ã€‘:")
                        print(f"ğŸ·ï¸  æ¥æº: {details['source']}")
                        print(f"ğŸ¯ MTLè¡¨è¾¾å¼: {details['mtl_expression']}")
                        print(f"ğŸ“ åˆ†ææ‘˜è¦: {details['summary']}")
                        print("-" * 30)
                
                # ç„¶åæ˜¾ç¤ºæŠ•ç¥¨è¯¦æƒ…
                self._display_voting_details(agent_responses)
            elif "è®¨è®º" in stage_name:
                # è®¨è®ºé˜¶æ®µæ˜¾ç¤ºè®¨è®ºæ‘˜è¦
                self._display_discussion_summary(agent_responses)
            else:
                # å…¶ä»–é˜¶æ®µæ˜¾ç¤ºå¸¸è§„ä¿¡æ¯
                print("ğŸ¤– å„Agentçš„å›ç­”:")
                print("-" * 50)
                for agent_name, response in agent_responses.items():
                    print(f"\nã€{agent_name}ã€‘:")
                    
                    # æå–å¹¶æ˜¾ç¤ºMTLè¡¨è¾¾å¼
                    mtl_expr = self._extract_mtl_expression(response)
                    print(f"ğŸ¯ MTLè¡¨è¾¾å¼: {mtl_expr}")
                    
                    # æ˜¾ç¤ºå›ç­”æ‘˜è¦ï¼ˆå‰300å­—ç¬¦ï¼‰
                    print(f"ğŸ“ åˆ†æè¿‡ç¨‹:")
                    if len(response) > 300:
                        print(f"{response[:300]}...")
                    else:
                        print(response)
                    
                    print(f"ğŸ“ å®Œæ•´å›ç­”é•¿åº¦: {len(response)} å­—ç¬¦")
                    print("-" * 30)
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        print("\nğŸ“Š é˜¶æ®µç»Ÿè®¡ä¿¡æ¯:")
        for key, value in results.items():
            if key != "agent_responses":  # é¿å…é‡å¤æ˜¾ç¤º
                print(f"   {key}: {value}")
        
        print(f"\nğŸ’¡ æ“ä½œé€‰é¡¹:")
        print(f"1. ç»§ç»­åˆ°ä¸‹ä¸€é˜¶æ®µ (continue)")
        print(f"2. ç»ˆæ­¢å¤„ç† (terminate)")
        print(f"3. æŸ¥çœ‹å®Œæ•´å›ç­” (view)")
        if "æŠ•ç¥¨" in stage_name and stage_result and hasattr(stage_result, 'candidate_details'):
            print(f"4. æŸ¥çœ‹å€™é€‰é¡¹è¯¦æƒ… (candidates)")
        
        max_choice = 4 if ("æŠ•ç¥¨" in stage_name and stage_result and hasattr(stage_result, 'candidate_details')) else 3
        
        while True:
            try:
                choice = input(f"\nè¯·è¾“å…¥é€‰æ‹© (1-{max_choice}): ").strip()
                
                if choice == "1":
                    return HumanDecision.CONTINUE
                elif choice == "2":
                    return HumanDecision.TERMINATE
                elif choice == "3":
                    # æ˜¾ç¤ºå®Œæ•´å›ç­”
                    if agent_responses:
                        print(f"\n{'='*60}")
                        print("ğŸ“– å®Œæ•´å›ç­”è¯¦æƒ…")
                        print(f"{'='*60}")
                        for agent_name, response in agent_responses.items():
                            print(f"\nã€{agent_name} - å®Œæ•´å›ç­”ã€‘:")
                            print(response)
                            print("-" * 50)
                        print("\nè¿”å›é€‰æ‹©èœå•...")
                        continue
                    else:
                        print("æ²¡æœ‰å¯æ˜¾ç¤ºçš„å›ç­”")
                        continue
                elif choice == "4" and "æŠ•ç¥¨" in stage_name and stage_result and hasattr(stage_result, 'candidate_details'):
                    # æ˜¾ç¤ºå€™é€‰é¡¹è¯¦æƒ…ï¼ˆä»…æŠ•ç¥¨é˜¶æ®µï¼‰
                    self._show_voting_candidates(stage_result)
                    continue
                else:
                    print(f"æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-{max_choice}!")
                    continue
                    
            except KeyboardInterrupt:
                print("\nç”¨æˆ·ä¸­æ–­ï¼Œé»˜è®¤ç»ˆæ­¢å¤„ç†")
                return HumanDecision.TERMINATE
            except Exception as e:
                print(f"è¾“å…¥é”™è¯¯: {e}")
                continue

    def _show_voting_candidates(self, stage_result: StageResult) -> None:
        """æ˜¾ç¤ºæŠ•ç¥¨å€™é€‰é¡¹è¯¦æƒ…"""
        print(f"\n{'='*60}")
        print("ğŸ—³ï¸  å€™é€‰é¡¹è¯¦æƒ…")
        print(f"{'='*60}")
        
        # ä»stage_resultä¸­è·å–å€™é€‰é¡¹è¯¦æƒ…
        if hasattr(stage_result, 'candidate_details') and stage_result.candidate_details:
            candidate_details = stage_result.candidate_details
            print("\nğŸ“‹ æ‰€æœ‰å€™é€‰é¡¹è¯¦ç»†ä¿¡æ¯:")
            
            for cand_id, details in candidate_details.items():
                print(f"\nã€{cand_id}ã€‘:")
                print(f"ğŸ·ï¸  æ¥æº: {details['source']}")
                print(f"ğŸ¯ MTLè¡¨è¾¾å¼: {details['mtl_expression']}")
                print(f"ğŸ“ åˆ†ææ‘˜è¦:")
                print(f"   {details['summary']}")
                print("-" * 50)
                
                # è¯¢é—®æ˜¯å¦æŸ¥çœ‹å®Œæ•´å›ç­”
                view_full = input(f"æ˜¯å¦æŸ¥çœ‹{cand_id}çš„å®Œæ•´åˆ†æï¼Ÿ(y/n): ").strip().lower()
                if view_full in ['y', 'yes', 'æ˜¯']:
                    print(f"\nğŸ“– ã€{cand_id}ã€‘å®Œæ•´åˆ†æ:")
                    print(details['full_response'])
                    print("-" * 50)
        else:
            print("\nâš ï¸  å€™é€‰é¡¹è¯¦æƒ…ä¿¡æ¯æœªæ‰¾åˆ°")
            print("è¿™å¯èƒ½æ˜¯å› ä¸ºæŠ•ç¥¨é˜¶æ®µè¿˜æœªæ‰§è¡Œæˆ–æ•°æ®ç»“æ„å‘ç”Ÿå˜åŒ–")
        
        print("\nè¿”å›é€‰æ‹©èœå•...")
    
    def _stage_1_independent_analysis(self, sentence: str, examples: str) -> StageResult:
        """ç¬¬ä¸€é˜¶æ®µï¼šç‹¬ç«‹åˆ†æ"""
        start_time = time.time()
        logger.info("=== ç¬¬ä¸€é˜¶æ®µï¼šç‹¬ç«‹åˆ†æ ===")
        
        # æ„å»ºprompt
        prompt = self.base_prompt.replace("[INPUT TEXT]", sentence)
        prompt = prompt.replace("[EXAMPLE]", examples)
        
        agent_responses = {}
        stage_token_usage = TokenUsage()
        
        for agent in self.agents:
            messages = [
                {"role": "system", "content": agent["system_prompt"]},
                {"role": "user", "content": prompt}
            ]
            
            try:
                response, token_usage = self._call_llm(agent["name"], messages)
                agent_responses[agent["name"]] = response
                
                # ç´¯è®¡tokenä½¿ç”¨
                stage_token_usage.prompt_tokens += token_usage.prompt_tokens
                stage_token_usage.completion_tokens += token_usage.completion_tokens
                stage_token_usage.total_tokens += token_usage.total_tokens
                
                logger.info(f"{agent['name']} ({agent['role']}) åˆ†æå®Œæˆ")
                
            except Exception as e:
                logger.error(f"Agent {agent['name']} åˆ†æå¤±è´¥: {e}")
                agent_responses[agent["name"]] = f"åˆ†æå¤±è´¥: {str(e)}"
        
        processing_time = time.time() - start_time
        
        return StageResult(
            stage_name="ç¬¬ä¸€é˜¶æ®µï¼šç‹¬ç«‹åˆ†æ",
            agent_responses=agent_responses,
            token_usage=stage_token_usage,
            processing_time=processing_time
        )
    
    def _stage_2_discussion(self, sentence: str, stage1_result: StageResult) -> StageResult:
        """ç¬¬äºŒé˜¶æ®µï¼šè®¨è®ºï¼ˆæœ€å¤š5è½®ï¼Œæ¯è½®åäººå·¥å†³ç­–ï¼‰"""
        start_time = time.time()
        logger.info("=== ç¬¬äºŒé˜¶æ®µï¼šè®¨è®º ===")
        
        max_rounds = 5
        discussion_history = []
        stage_token_usage = TokenUsage()
        final_responses = {}
        
        # æ„å»ºè®¨è®ºprompt
        discussion_prompt = f"""
è¯·å‚ä¸å¤šæ™ºèƒ½ä½“è®¨è®ºï¼Œåˆ†æä»¥ä¸‹å¥å­çš„MTLè¡¨è¾¾å¼ã€‚

åŸå¥å­: "{sentence}"

å„Agentçš„åˆå§‹åˆ†æ:
"""
        for agent_name, response in stage1_result.agent_responses.items():
            discussion_prompt += f"\n{agent_name}: {response}\n"
        
        discussion_prompt += """
è¯·ä»”ç»†åˆ†ææ‰€æœ‰è§£é‡Šçš„åˆç†æ€§ï¼Œé€šè¿‡è®¨è®ºå°è¯•è¾¾æˆä¸€ä¸ªæœ€ç»ˆçš„ã€æœ€åˆç†çš„MTLè¡¨è¾¾å¼ã€‚
è¯·æä¾›ä½ è®¤ä¸ºæœ€å‡†ç¡®çš„MTLè¡¨è¾¾å¼å’Œæ¨ç†è¿‡ç¨‹ã€‚
"""
        
        for round_num in range(max_rounds):
            logger.info(f"è®¨è®ºè½®æ¬¡ {round_num + 1}")
            round_responses = {}
            round_token_usage = TokenUsage()
            
            for agent in self.agents:
                messages = [
                    {"role": "system", "content": agent["system_prompt"]},
                    {"role": "user", "content": discussion_prompt}
                ]
                
                if discussion_history:
                    history_text = "\n".join(discussion_history)
                    messages.append({"role": "user", "content": f"ä¹‹å‰çš„è®¨è®º:\n{history_text}\n\nè¯·åŸºäºè®¨è®ºå†å²ç»§ç»­åˆ†æï¼š"})
                
                try:
                    response, token_usage = self._call_llm(agent["name"], messages)
                    round_responses[agent["name"]] = response
                    
                    # ç´¯è®¡tokenä½¿ç”¨
                    round_token_usage.prompt_tokens += token_usage.prompt_tokens
                    round_token_usage.completion_tokens += token_usage.completion_tokens
                    round_token_usage.total_tokens += token_usage.total_tokens
                    
                except Exception as e:
                    logger.error(f"Agent {agent['name']} è®¨è®ºå¤±è´¥: {e}")
                    round_responses[agent["name"]] = f"è®¨è®ºå¤±è´¥: {str(e)}"
            
            # ç´¯è®¡åˆ°æ€»tokenä½¿ç”¨
            stage_token_usage.prompt_tokens += round_token_usage.prompt_tokens
            stage_token_usage.completion_tokens += round_token_usage.completion_tokens
            stage_token_usage.total_tokens += round_token_usage.total_tokens
            
            # æ˜¾ç¤ºæœ¬è½®è®¨è®ºç»“æœå¹¶è¯·æ±‚äººå·¥å†³ç­–
            print(f"\n{'='*60}")
            print(f"ğŸ“ ç¬¬{round_num + 1}è½®è®¨è®ºç»“æœ")
            print(f"{'='*60}")
            
            # æ˜¾ç¤ºæ¯ä¸ªAgentçš„ç»“è®º
            self._display_discussion_summary(round_responses)
            
            # è®°å½•è®¨è®ºå†å²
            discussion_history.append(f"ç¬¬{round_num + 1}è½®è®¨è®º:\n" +
                                    "\n".join([f"{name}: {resp[:200]}..." for name, resp in round_responses.items()]))
            
            final_responses = round_responses
            
            # å¦‚æœä¸æ˜¯æœ€åä¸€è½®ï¼Œè¯¢é—®æ˜¯å¦ç»§ç»­
            if round_num < max_rounds - 1:
                decision = self._request_human_decision(f"ç¬¬{round_num + 1}è½®è®¨è®ºå®Œæˆ", {
                    "å½“å‰è½®æ¬¡": f"{round_num + 1}/{max_rounds}",
                    "æœ¬è½®å¤„ç†æ—¶é—´": f"{(time.time() - start_time):.2f}ç§’",
                    "æœ¬è½®Tokenä½¿ç”¨": round_token_usage.total_tokens,
                    "ç´¯è®¡Tokenä½¿ç”¨": stage_token_usage.total_tokens
                }, round_responses)
                
                if decision == HumanDecision.TERMINATE:
                    logger.info(f"äººå·¥å†³ç­–ï¼šåœ¨ç¬¬{round_num + 1}è½®åç»ˆæ­¢è®¨è®º")
                    break
                else:
                    logger.info(f"äººå·¥å†³ç­–ï¼šç»§ç»­ç¬¬{round_num + 2}è½®è®¨è®º")
            else:
                logger.info("å·²å®Œæˆæœ€å¤§è®¨è®ºè½®æ¬¡")
        
        processing_time = time.time() - start_time
        
        return StageResult(
            stage_name="ç¬¬äºŒé˜¶æ®µï¼šè®¨è®º",
            agent_responses=final_responses,
            token_usage=stage_token_usage,
            processing_time=processing_time
        )
    
    def _stage_3_voting(self, sentence: str, stage1_result: StageResult, stage2_result: StageResult) -> StageResult:
        """ç¬¬ä¸‰é˜¶æ®µï¼šæŠ•ç¥¨"""
        start_time = time.time()
        logger.info("=== ç¬¬ä¸‰é˜¶æ®µï¼šæŠ•ç¥¨ ===")
        
        # æ”¶é›†æ‰€æœ‰å€™é€‰ç­”æ¡ˆï¼ˆåŒ…å«å®Œæ•´ä¿¡æ¯ï¼‰
        candidates = {}
        candidate_details = {}
        candidate_id = 1
        
        # ä»ç¬¬ä¸€é˜¶æ®µæ”¶é›†å€™é€‰ç­”æ¡ˆ
        for agent_name, response in stage1_result.agent_responses.items():
            cand_key = f"å€™é€‰{candidate_id}"
            mtl_expr = self._extract_mtl_expression(response)
            candidates[cand_key] = f"{agent_name}çš„ç‹¬ç«‹åˆ†æ: {mtl_expr}"
            candidate_details[cand_key] = {
                "source": f"ç¬¬ä¸€é˜¶æ®µ - {agent_name}",
                "mtl_expression": mtl_expr,
                "full_response": response,
                "summary": response[:300] + "..." if len(response) > 300 else response
            }
            candidate_id += 1
        
        # ä»ç¬¬äºŒé˜¶æ®µæ”¶é›†å€™é€‰ç­”æ¡ˆ
        for agent_name, response in stage2_result.agent_responses.items():
            cand_key = f"å€™é€‰{candidate_id}"
            mtl_expr = self._extract_mtl_expression(response)
            candidates[cand_key] = f"{agent_name}çš„è®¨è®ºç»“æœ: {mtl_expr}"
            candidate_details[cand_key] = {
                "source": f"ç¬¬äºŒé˜¶æ®µ - {agent_name}",
                "mtl_expression": mtl_expr,
                "full_response": response,
                "summary": response[:300] + "..." if len(response) > 300 else response
            }
            candidate_id += 1
        
        # æ„å»ºæŠ•ç¥¨prompt
        voting_prompt = f"""
è¯·å¯¹ä»¥ä¸‹MTLè¡¨è¾¾å¼å€™é€‰é¡¹è¿›è¡ŒæŠ•ç¥¨ï¼Œé€‰æ‹©æœ€èƒ½å‡†ç¡®è¡¨ç¤ºå¥å­å«ä¹‰çš„è¡¨è¾¾å¼ã€‚

åŸå¥å­: "{sentence}"

å€™é€‰ç­”æ¡ˆ:
"""
        for cand_id, cand_text in candidates.items():
            voting_prompt += f"{cand_id}: {cand_text}\n"
        
        voting_prompt += """
è¯·ä»”ç»†åˆ†ææ¯ä¸ªå€™é€‰è¡¨è¾¾å¼ï¼Œå¹¶æŠ•ç¥¨é€‰æ‹©æœ€ä½³ç­”æ¡ˆã€‚
è¯·å›å¤æ ¼å¼ï¼šæˆ‘æŠ•ç¥¨ç»™ï¼š[å€™é€‰ID]ï¼Œç†ç”±ï¼š[æŠ•ç¥¨ç†ç”±]
"""
        
        agent_responses = {}
        stage_token_usage = TokenUsage()
        
        for agent in self.agents:
            messages = [
                {"role": "system", "content": agent["system_prompt"]},
                {"role": "user", "content": voting_prompt}
            ]
            
            try:
                response, token_usage = self._call_llm(agent["name"], messages)
                agent_responses[agent["name"]] = response
                
                # ç´¯è®¡tokenä½¿ç”¨
                stage_token_usage.prompt_tokens += token_usage.prompt_tokens
                stage_token_usage.completion_tokens += token_usage.completion_tokens
                stage_token_usage.total_tokens += token_usage.total_tokens
                
                logger.info(f"{agent['name']} æŠ•ç¥¨å®Œæˆ")
                
            except Exception as e:
                logger.error(f"Agent {agent['name']} æŠ•ç¥¨å¤±è´¥: {e}")
                agent_responses[agent["name"]] = f"æŠ•ç¥¨å¤±è´¥: {str(e)}"
        
        processing_time = time.time() - start_time
        
        # åˆ›å»ºåŒ…å«å€™é€‰é¡¹è¯¦æƒ…çš„ç»“æœ
        result = StageResult(
            stage_name="ç¬¬ä¸‰é˜¶æ®µï¼šæŠ•ç¥¨",
            agent_responses=agent_responses,
            token_usage=stage_token_usage,
            processing_time=processing_time
        )
        
        # å°†å€™é€‰é¡¹è¯¦æƒ…æ·»åŠ åˆ°ç»“æœä¸­ï¼ˆé€šè¿‡æ‰©å±•å±æ€§ï¼‰
        result.candidate_details = candidate_details
        
        return result
    
    def _stage_4_arbitration(self, sentence: str, stage1_result: StageResult, 
                           stage2_result: StageResult, stage3_result: StageResult) -> StageResult:
        """ç¬¬å››é˜¶æ®µï¼šä»²è£"""
        start_time = time.time()
        logger.info("=== ç¬¬å››é˜¶æ®µï¼šä»²è£ ===")
        
        # æ„å»ºä»²è£prompt
        arbitration_prompt = f"""
ä½œä¸ºMTLä¸“å®¶ï¼Œè¯·å¯¹ä»¥ä¸‹å¤æ‚æ¡ˆä¾‹è¿›è¡Œæœ€ç»ˆè£å†³ã€‚

åŸå¥å­: "{sentence}"

å¤„ç†è¿‡ç¨‹æ€»ç»“:
ç¬¬ä¸€é˜¶æ®µ - ç‹¬ç«‹åˆ†æç»“æœ:
"""
        for agent_name, response in stage1_result.agent_responses.items():
            arbitration_prompt += f"{agent_name}: {response[:300]}...\n"
        
        arbitration_prompt += "\nç¬¬äºŒé˜¶æ®µ - è®¨è®ºç»“æœ:\n"
        for agent_name, response in stage2_result.agent_responses.items():
            arbitration_prompt += f"{agent_name}: {response[:300]}...\n"
        
        arbitration_prompt += "\nç¬¬ä¸‰é˜¶æ®µ - æŠ•ç¥¨ç»“æœ:\n"
        for agent_name, response in stage3_result.agent_responses.items():
            arbitration_prompt += f"{agent_name}: {response[:300]}...\n"
        
        arbitration_prompt += """

è¯·æä¾›æœ€ç»ˆçš„ä¸“å®¶åˆ¤æ–­:
1. è¯¥å¥å­çš„æœ€å‡†ç¡®çš„MTLè¡¨è¾¾å¼æ˜¯ä»€ä¹ˆï¼Ÿ
2. ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªè¡¨è¾¾å¼ï¼Ÿ

è¯·æä¾›è¯¦ç»†çš„åˆ†æå’Œæœ€ç»ˆçš„MTLè¡¨è¾¾å¼ã€‚
"""
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªagentä½œä¸ºä»²è£è€…
        arbitrator = self.agents[0]
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„MTLé€»è¾‘ä¸“å®¶ï¼Œè´Ÿè´£å¯¹å¤æ‚çš„æ¡ˆä¾‹è¿›è¡Œæœ€ç»ˆè£å†³ã€‚"},
            {"role": "user", "content": arbitration_prompt}
        ]
        
        stage_token_usage = TokenUsage()
        
        try:
            response, token_usage = self._call_llm(arbitrator["name"], messages)
            agent_responses = {f"ä»²è£è€…_{arbitrator['name']}": response}
            
            stage_token_usage = token_usage
            logger.info("ä»²è£å®Œæˆ")
            
        except Exception as e:
            logger.error(f"ä»²è£å¤±è´¥: {e}")
            agent_responses = {"ä»²è£è€…": f"ä»²è£å¤±è´¥: {str(e)}"}
        
        processing_time = time.time() - start_time
        
        return StageResult(
            stage_name="ç¬¬å››é˜¶æ®µï¼šä»²è£",
            agent_responses=agent_responses,
            token_usage=stage_token_usage,
            processing_time=processing_time
        )
    
    def process(self, sentence: str) -> ProcessResult:
        """å®Œæ•´å¤„ç†æµç¨‹"""
        start_time = time.time()
        logger.info(f"å¼€å§‹å¤„ç†å¥å­: {sentence}")
        
        # é‡ç½®tokenç»Ÿè®¡
        self.total_token_usage = TokenUsage()
        stage_results = []
        final_mtl_expression = None
        termination_reason = "å®Œæˆæ‰€æœ‰é˜¶æ®µ"
        
        try:
            # è·å–ç›¸ä¼¼ç¤ºä¾‹
            examples = self._get_top_examples(sentence)
            logger.info("è·å–ç›¸ä¼¼ç¤ºä¾‹å®Œæˆ")
            
            # ç¬¬ä¸€é˜¶æ®µï¼šç‹¬ç«‹åˆ†æ
            stage1_result = self._stage_1_independent_analysis(sentence, examples)
            stage_results.append(stage1_result)
            
            # äººå·¥å†³ç­–ï¼šæ˜¯å¦ç»§ç»­åˆ°ç¬¬äºŒé˜¶æ®µ
            decision = self._request_human_decision("ç¬¬ä¸€é˜¶æ®µå®Œæˆ", {
                "æˆåŠŸåˆ†æçš„Agentæ•°": len([r for r in stage1_result.agent_responses.values() if "å¤±è´¥" not in r]),
                "å¤„ç†æ—¶é—´": f"{stage1_result.processing_time:.2f}ç§’",
                "Tokenä½¿ç”¨": stage1_result.token_usage.total_tokens
            }, stage1_result.agent_responses)
            stage1_result.human_decision = decision
            
            if decision == HumanDecision.TERMINATE:
                termination_reason = "ç¬¬ä¸€é˜¶æ®µåäººå·¥ç»ˆæ­¢"
                # å°è¯•ä»ç¬¬ä¸€é˜¶æ®µæå–MTLè¡¨è¾¾å¼
                for response in stage1_result.agent_responses.values():
                    mtl_match = re.search(r'```(.*?)```', response, re.DOTALL)
                    if mtl_match:
                        final_mtl_expression = mtl_match.group(1).strip()
                        break
                return self._create_result(sentence, start_time, stage_results, final_mtl_expression, termination_reason)
            
            # ç¬¬äºŒé˜¶æ®µï¼šè®¨è®º
            stage2_result = self._stage_2_discussion(sentence, stage1_result)
            stage_results.append(stage2_result)
            
            # äººå·¥å†³ç­–ï¼šæ˜¯å¦ç»§ç»­åˆ°ç¬¬ä¸‰é˜¶æ®µ
            decision = self._request_human_decision("ç¬¬äºŒé˜¶æ®µå®Œæˆ", {
                "è®¨è®ºè½®æ¬¡": "5è½®",
                "å¤„ç†æ—¶é—´": f"{stage2_result.processing_time:.2f}ç§’",
                "Tokenä½¿ç”¨": stage2_result.token_usage.total_tokens
            }, stage2_result.agent_responses)
            stage2_result.human_decision = decision
            
            if decision == HumanDecision.TERMINATE:
                termination_reason = "ç¬¬äºŒé˜¶æ®µåäººå·¥ç»ˆæ­¢"
                # å°è¯•ä»ç¬¬äºŒé˜¶æ®µæå–MTLè¡¨è¾¾å¼
                for response in stage2_result.agent_responses.values():
                    mtl_match = re.search(r'```(.*?)```', response, re.DOTALL)
                    if mtl_match:
                        final_mtl_expression = mtl_match.group(1).strip()
                        break
                return self._create_result(sentence, start_time, stage_results, final_mtl_expression, termination_reason)
            
            # ç¬¬ä¸‰é˜¶æ®µï¼šæŠ•ç¥¨
            stage3_result = self._stage_3_voting(sentence, stage1_result, stage2_result)
            stage_results.append(stage3_result)
            
            # äººå·¥å†³ç­–ï¼šæ˜¯å¦ç»§ç»­åˆ°ç¬¬å››é˜¶æ®µ
            decision = self._request_human_decision("ç¬¬ä¸‰é˜¶æ®µå®Œæˆ", {
                "æŠ•ç¥¨å®Œæˆ": "æ‰€æœ‰Agentå·²æŠ•ç¥¨",
                "å¤„ç†æ—¶é—´": f"{stage3_result.processing_time:.2f}ç§’",
                "Tokenä½¿ç”¨": stage3_result.token_usage.total_tokens
            }, stage3_result.agent_responses, stage3_result)
            stage3_result.human_decision = decision
            
            if decision == HumanDecision.TERMINATE:
                termination_reason = "ç¬¬ä¸‰é˜¶æ®µåäººå·¥ç»ˆæ­¢"
                # å°è¯•ä»æŠ•ç¥¨ç»“æœæå–MTLè¡¨è¾¾å¼
                for response in stage3_result.agent_responses.values():
                    mtl_match = re.search(r'```(.*?)```', response, re.DOTALL)
                    if mtl_match:
                        final_mtl_expression = mtl_match.group(1).strip()
                        break
                return self._create_result(sentence, start_time, stage_results, final_mtl_expression, termination_reason)
            
            # ç¬¬å››é˜¶æ®µï¼šä»²è£
            stage4_result = self._stage_4_arbitration(sentence, stage1_result, stage2_result, stage3_result)
            stage_results.append(stage4_result)
            
            # äººå·¥å†³ç­–ï¼šæœ€ç»ˆç¡®è®¤
            decision = self._request_human_decision("ç¬¬å››é˜¶æ®µå®Œæˆï¼ˆæœ€ç»ˆï¼‰", {
                "ä»²è£å®Œæˆ": "ä¸“å®¶ä»²è£å·²å®Œæˆ",
                "å¤„ç†æ—¶é—´": f"{stage4_result.processing_time:.2f}ç§’",
                "Tokenä½¿ç”¨": stage4_result.token_usage.total_tokens
            }, stage4_result.agent_responses)
            stage4_result.human_decision = decision
            
            # ä»ä»²è£ç»“æœæå–æœ€ç»ˆMTLè¡¨è¾¾å¼
            for response in stage4_result.agent_responses.values():
                mtl_match = re.search(r'```(.*?)```', response, re.DOTALL)
                if mtl_match:
                    final_mtl_expression = mtl_match.group(1).strip()
                    break
            
            if decision == HumanDecision.TERMINATE:
                termination_reason = "ç¬¬å››é˜¶æ®µåäººå·¥ç¡®è®¤ç»ˆæ­¢"
            else:
                termination_reason = "å®Œæˆæ‰€æœ‰é˜¶æ®µ"
            
        except Exception as e:
            logger.error(f"å¤„ç†è¿‡ç¨‹å‡ºé”™: {e}")
            termination_reason = f"ç³»ç»Ÿé”™è¯¯: {str(e)}"
        
        return self._create_result(sentence, start_time, stage_results, final_mtl_expression, termination_reason)
    
    def _create_result(self, sentence: str, start_time: float, stage_results: List[StageResult],
                      final_mtl_expression: Optional[str], termination_reason: str) -> ProcessResult:
        """åˆ›å»ºå¤„ç†ç»“æœ"""
        total_processing_time = time.time() - start_time
        
        return ProcessResult(
            input_sentence=sentence,
            final_mtl_expression=final_mtl_expression,
            total_token_usage=self.total_token_usage,
            total_processing_time=total_processing_time,
            stage_results=stage_results,
            termination_reason=termination_reason
        )
    
    def save_result(self, result: ProcessResult, output_file: str):
        """ä¿å­˜å¤„ç†ç»“æœ"""
        Path(output_file).parent.mkdir(parents=True, exist_ok=True)
        
        # æ”¶é›†æ¨¡å‹é…ç½®ä¿¡æ¯
        model_info = {
            "agents": [
                {
                    "name": agent["name"],
                    "role": agent["role"],
                    "model": agent["model"],
                    "temperature": agent["temperature"]
                }
                for agent in self.agents
            ],
            "total_agents": len(self.agents),
            "sentence_model": "sentence-transformers/all-MiniLM-L6-v2"
        }
        
        save_data = {
            "input_sentence": result.input_sentence,
            "final_mtl_expression": result.final_mtl_expression,
            "termination_reason": result.termination_reason,
            "total_processing_time": result.total_processing_time,
            "total_token_usage": asdict(result.total_token_usage),
            "model_info": model_info,
            "stage_results": [
                {
                    "stage_name": stage.stage_name,
                    "processing_time": stage.processing_time,
                    "token_usage": asdict(stage.token_usage),
                    "human_decision": stage.human_decision.value if stage.human_decision else None,
                    "agent_responses": stage.agent_responses,
                    "candidate_details": getattr(stage, 'candidate_details', None)
                }
                for stage in result.stage_results
            ]
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

def main():
    """ä¸»å‡½æ•°æ¼”ç¤º"""
    print("=== NL2MTL ===\n")
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = SimplifiedNL2MTL()
    
    # æµ‹è¯•å¥å­
    test_sentence = "After receiving the signal, the system must respond within 10 seconds."
    
    print(f"å¤„ç†å¥å­: {test_sentence}")
    print("-" * 60)
    try:
        # æ‰§è¡Œå¤„ç†
        result = processor.process(test_sentence)
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\næœ€ç»ˆMTLè¡¨è¾¾å¼: {result.final_mtl_expression}")
        print(f"ç»ˆæ­¢åŸå› : {result.termination_reason}")
        print(f"æ€»å¤„ç†æ—¶é—´: {result.total_processing_time:.2f}ç§’")
        print(f"æ€»Tokenä½¿ç”¨: {result.total_token_usage.total_tokens}")
        
        # ä¿å­˜ç»“æœ
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        output_file = f"data/output/simplified_{timestamp}.json"
        processor.save_result(result, output_file)
        
    except Exception as e:
        print(f"å¤„ç†å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
        